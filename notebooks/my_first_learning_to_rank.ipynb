{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec(\"my_first_ltr\"): # type: ignore\n",
    "    %pip install -qqq git+https://github.com/algolia/my-first-learning-to-rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Learning To Rank ?\n",
    "\n",
    "As the name indicates, it's training to rank stuff \n",
    "\n",
    "## Why rank ? And what's ranking here ?\n",
    "\n",
    "## What's ranking model ?\n",
    "\n",
    "it's a function that maps an item to it's relevance score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It all starts with data\n",
    "\n",
    "- a user search history\n",
    "- a subset of imdb dataset\n",
    "\n",
    "We did all the nasty pre-processing and cleaning for you - so you can just have fun! \n",
    "\n",
    "\n",
    "At home, you can try with your search history if you'd like!\n",
    "# FIXME: if so time, clean up the data prep script in a notebook\n",
    "\n",
    "## What's our score here ?\n",
    "\n",
    "- What's your idea ?\n",
    "\n",
    "- We consider that if the user watched the movie, it was highly relevant\n",
    "- We consider that if the user added it to it's watchlist, it was relevant, but not the right mood at that time\n",
    "- We consider that if the user clicked on a movie, it showed some interest but it wasn't that relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_first_ltr.utils import load_dataset\n",
    "\n",
    "# FIXME: check if once repo is public that loading works\n",
    "dataset = load_dataset(local=True)\n",
    "dataset.head(5)\n",
    "\n",
    "\n",
    "\n",
    "# FIXME: stuff we've learn and you should not waist time on\n",
    "# - negative samples\n",
    "\n",
    "\n",
    "# FIXME: show a specific query with results examples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are our features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then comes a model\n",
    "\n",
    "PointWise\n",
    "PairWise\n",
    "ListWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_first_ltr.train_utils import build_pool, dataset_split\n",
    "\n",
    "\n",
    "train_df, test_df, val_df = dataset_split(dataset)\n",
    "\n",
    "train_pool = build_pool(train_df, \"train\")\n",
    "test_pool = build_pool(test_df, \"test\")\n",
    "val_pool = build_pool(val_df, \"validation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE pointwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostRanker\n",
    "\n",
    "model = CatBoostRanker(loss_function=\"RMSE\", depth=6, learning_rate=0.15, thread_count=1, iterations=500, random_seed=0)\n",
    "                    #    custom_metric=[\"NDCG:top=-1;type=Base;denominator=LogPosition;hints=skip_train~false\"]\n",
    "#                        )\n",
    "\n",
    "# model = CatBoost({\"loss_function\":\"YetiRank\", \"depth\":6, \"learning_rate\":0.15, \"thread_count\":1, \"iterations\":500, \"random_seed\":0, \"verbose\":False})\n",
    "#                        custom_metric=[\"NDCG:top=2;type=Base;denominator=LogPosition;hints=skip_train~false\"])\n",
    "\n",
    "# model = CatBoostRegressor(iterations=10000, depth=6, learning_rate=0.15, loss_function='RMSE', verbose=50)\n",
    "\n",
    "model.fit(train_pool, eval_set=test_pool, plot=True, metric_period=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "val_df[\"pred_score\"] = model.predict(val_pool)\n",
    "\n",
    "\n",
    "results = val_df[[\"score\", \"pred_score\"]]\n",
    "\n",
    "print(\"Predictions vs Actuals:\")\n",
    "print(results.head())\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(results[\"score\"], results[\"pred_score\"]))\n",
    "mae = mean_absolute_error(results[\"score\"], results[\"pred_score\"])\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoost, Pool\n",
    "from my_first_ltr.train_utils import keep_input_features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cross_dataset_shape_cascade( m: CatBoost, X: pd.DataFrame, pools: dict[str, Pool]) -> None:\n",
    "    \"\"\"Shap values average per feature accross all dataset.\"\"\"\n",
    "    df_feature_importance = pd.DataFrame(\n",
    "        data={k: m.get_feature_importance(pool) for k, pool in pools.items()}, index=X.columns\n",
    "    )\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    df_feature_importance.plot.barh(figsize=(10, 12))\n",
    "    plt.title(\"cross dataset - importance of each feature\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.savefig(os.path.join(path, f\"features_importances_{config.impl_name}.png\"), format=\"png\", bbox_inches=\"tight\")\n",
    "\n",
    "cross_dataset_shape_cascade(model, keep_input_features(train_df), {\"train\": train_pool, \"test\": test_pool, \"val\": val_pool})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
